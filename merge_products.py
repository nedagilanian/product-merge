import pandas as pd
import requests
from urllib.parse import quote
import time

# === 1. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ===
jonoobmall = pd.read_csv("jonoobmall.csv")
kalakhane = pd.read_csv("kalakhane.csv")
dehshikhstore = pd.read_csv("dehshikhstore.csv")

print("ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§:", len(jonoobmall) + len(kalakhane) + len(dehshikhstore))

# === 2. ÛŒÚ©Ø³Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ===
rename_map = {
    'Ù†Ø§Ù…': 'title',
    'Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„': 'title',
    'Ù†Ø§Ù… Ú©Ø§Ù„Ø§': 'title',
    'product_name': 'title',
    'Ù‚ÛŒÙ…Øª': 'price',
    'Ù‚ÛŒÙ…Øª Ø§ØµÙ„ÛŒ': 'price',
    'Ù‚ÛŒÙ…Øª ÙØ±ÙˆØ´ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡': 'sale_price',
    'Ø¨Ø±Ù†Ø¯': 'brand',
    'Ø¨Ø±Ù†Ø¯Ù‡Ø§': 'brand',
    'ØªÙˆØ¶ÛŒØ­Ø§Øª': 'description',
    'ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡': 'short_desc',
    'ØªØµØ§ÙˆÛŒØ±': 'images'
}

for df in [jonoobmall, kalakhane, dehshikhstore]:
    df.rename(columns=rename_map, inplace=True)

# Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø³ØªÙˆÙ† title Ø¯Ø± Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
for df_name, df in [("jonoobmall", jonoobmall), ("kalakhane", kalakhane), ("dehshikhstore", dehshikhstore)]:
    if 'title' not in df.columns:
        print(f"âŒ ÙØ§ÛŒÙ„ {df_name} Ø³ØªÙˆÙ† title Ù†Ø¯Ø§Ø±Ø¯! Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆØ¯.")
        raise SystemExit

# === 3. Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ===
all_data = pd.concat([jonoobmall, kalakhane, dehshikhstore], ignore_index=True)
print("âœ… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:", list(all_data.columns))

# === 4. Ø­Ø°Ù Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ ===
before = len(all_data)
all_data.drop_duplicates(subset=['title'], inplace=True)
print(f"ğŸ§¹ Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯: {before - len(all_data)} Ù…ÙˆØ±Ø¯")
print(f"ğŸ”¢ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ù‡Ø§ÛŒÛŒ: {len(all_data)}")

# === 5. ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§ ===
def get_price_from_digikala(product_name):
    try:
        url = f"https://api.digikala.com/v1/search/?q={quote(product_name)}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        data = res.json()
        products = data.get("data", {}).get("products", [])
        if not products:
            return None
        return products[0].get("default_variant", {}).get("price", {}).get("selling_price")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ {product_name}: {e}")
        return None

# === 6. ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§ ===
def get_product_details_from_digikala(product_name):
    try:
        # Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø­ØµÙˆÙ„
        search_url = f"https://api.digikala.com/v1/search/?q={quote(product_name)}"
        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        data = response.json()
        products = data.get("data", {}).get("products", [])
        if not products:
            return None, None

        # Ú¯Ø±ÙØªÙ† Ø´Ù†Ø§Ø³Ù‡ Ù…Ø­ØµÙˆÙ„
        product_id = products[0].get("id")
        if not product_id:
            return None, None

        # Ù…Ø±Ø­Ù„Ù‡ Û²: Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„
        details_url = f"https://api.digikala.com/v1/product/{product_id}/"
        details_res = requests.get(details_url, headers={'User-Agent': 'Mozilla/5.0'})
        details_data = details_res.json()

        product_data = details_data.get("data", {}).get("product", {})

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆØ¶ÛŒØ­Ø§Øª
        desc = product_data.get("review", {}).get("description", "")
        if not desc:
            desc = product_data.get("seo_meta", {}).get("description", "")

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        specs = product_data.get("specifications", [])
        specs_text = ""
        for group in specs:
            for attr in group.get("attributes", []):
                name = attr.get("title_fa", "") or attr.get("title_en", "")
                values = [v.get("title", "") for v in attr.get("values", [])]
                if name and values:
                    specs_text += f"{name}: {'ØŒ '.join(values)}\n"

        return desc.strip(), specs_text.strip()

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… ÙˆØ§Ú©Ø´ÛŒ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ø±Ø§ÛŒ {product_name}: {e}")
        return None, None

# === 7. Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øª Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª ===
updated_prices = []
updated_descs = []
updated_specs = []

print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§...")

for index, row in all_data.iterrows():
    title = str(row.get('title', '')).strip()
    if not title:
        print(f"âš ï¸ Ø±Ø¯ÛŒÙ {index} Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù† Ø§Ø³ØªØŒ Ø±Ø¯ Ø´Ø¯.")
        continue

    # Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª
    new_price = get_price_from_digikala(title)
    updated_prices.append(new_price if new_price else row.get('price', None))

    # Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (ÙÙ‚Ø· Ø§Ú¯Ø± ØªÙˆØ¶ÛŒØ­ Ù†Ø§Ù‚Øµ Ø§Ø³Øª)
    desc, specs = None, None
    if pd.isna(row.get('description')) or len(str(row.get('description')).strip()) < 20:
        desc, specs = get_product_details_from_digikala(title)

    updated_descs.append(desc if desc else row.get('description', ''))
    updated_specs.append(specs if specs else "")

    print(f"{index+1}/{len(all_data)} | {title[:40]} â†’ ğŸ’° {new_price if new_price else 'âŒ'} | ğŸ“ ØªÙˆØ¶ÛŒØ­: {'âœ…' if desc else 'âŒ'}")

    time.sleep(1.5)  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù† ØªÙˆØ³Ø· Ø³Ø±ÙˆØ± Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§

# === 8. Ø§ÙØ²ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… ===
all_data['digikala_price'] = updated_prices
all_data['digikala_description'] = updated_descs
all_data['digikala_specs'] = updated_specs

# === 9. Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ===
output_name = "final_products_with_digikala.csv"
all_data.to_csv(output_name, index=False, encoding='utf-8-sig')
print(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_name} âœ…")
