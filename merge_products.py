import pandas as pd
import requests
from urllib.parse import quote

# -------------------------------
# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§
# -------------------------------
def get_price_from_digikala(product_name):
    try:
        search_url = f"https://api.digikala.com/v1/search/?q={quote(product_name)}"
        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        data = response.json()
        products = data.get("data", {}).get("products", [])
        if not products:
            return None
        
        first = products[0]
        title = first["title_fa"]
        price = first.get("default_variant", {}).get("price", {}).get("selling_price", None)
        if price:
            return price
        return None
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ {product_name}: {e}")
        return None

# -------------------------------
# Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù‡ Ø¨Ø¹Ø¯ Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒØª Ù…ÛŒØ§Ø¯
# -------------------------------

# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ùˆ Ù…ÛŒâ€ŒØ®ÙˆÙ†ÛŒÙ…
jonoobmall = pd.read_csv("jonoobmall.csv")
kalakhane = pd.read_csv("kalakhane.csv")
dehshikhstore = pd.read_csv("dehshikhstore.csv")

# Ø§Ø¯ØºØ§Ù… Ø§ÙˆÙ„ÛŒÙ‡
all_data = pd.concat([jonoobmall, kalakhane, dehshikhstore], ignore_index=True)
print("ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§:", len(all_data))

# Ù…Ø±Ø­Ù„Ù‡ Û´: ÛŒÚ©ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
# (Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒØª Ø¨Ø±Ø§ÛŒ rename Ùˆ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù‡Ù…ÙˆÙ†Ø¬Ø§ Ø¨Ù…ÙˆÙ†Ù†)

# Ù…Ø±Ø­Ù„Ù‡ Ûµ: Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
# (Ú©Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ drop_duplicates Ù‡Ù…ÙˆÙ†Ø¬Ø§ Ø¨Ù…ÙˆÙ†Ù‡)

# -------------------------------
# Ù…Ø±Ø­Ù„Ù‡ Û¶: Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øª Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§
# -------------------------------
updated = 0
for i, row in all_data.iterrows():
    title = row['title']
    new_price = get_price_from_digikala(title)
    if new_price:
        all_data.at[i, 'price'] = new_price
        updated += 1

print(f"ğŸ’° Ù‚ÛŒÙ…Øª {updated} Ù…Ø­ØµÙˆÙ„ Ø§Ø² Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯.")
